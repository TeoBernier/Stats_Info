{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indépendance\n",
    "\n",
    "On va ici faire plus de simulation que dans la partie dénombrement, on utilisera ainsi beaucoup la librairie random de python, et aussi peut-être, numpy.random ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "#Imaginons qu'on lance 2 dé :\n",
    "(randint(1, 6), randint(1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si l'on fait maintenant 100 000 lancés :\n",
    "jets_comprehension = [(randint(1,6), randint(1,6)) for _ in range(100000)]\n",
    "\n",
    "#On vous montre ici une façon très mauvaise de le faire !!\n",
    "\n",
    "#Il aurait en effet était préférable d'utiliser numpy :\n",
    "\n",
    "#ATTENTION, le randint de numpy est exclusif ([a, b[), alors que celui natif en python est inclusif ([a, b])\n",
    "#on utilise donc random.randint(1, 6) mais numpy.random.randint(1, 7) !\n",
    "\n",
    "jets_numpy = np.random.randint(1, 7, (100000, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit [(randint(1,6), randint(1,6)) for _ in range(100000)]\n",
    "%timeit np.random.randint(1, 7, (100000, 2))\n",
    "#On voit ici que la version avec numpy est environ 50 fois plus rapide\n",
    "\n",
    "print(f'\\nLes 5 premiers jets de notre tableau : \\n{jets_comprehension[:5]}')\n",
    "print(f'\\nLes 5 premiers jets du tableau retourné par numpy : \\n{jets_numpy[:5]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on peut alors faire un peu ce que l'on veut avec notre echantillonage:\n",
    "\n",
    "#la formule ici a l'air un peu barbare, mais en vrai rien de bien dur à comprendre !\n",
    "\n",
    "print(\"Avec np.sum et le parcours avec numpy\")\n",
    "%timeit np.sum(np.all(jets_numpy[:] == (1, 1), axis = -1)) / len(jets_numpy)\n",
    "\n",
    "#normalement, si on fait np.array([1,2]) == np.array([1,2]), on aura [True, True]\n",
    "#si maintenant on fait   np.array([1,2]) == np.array([2,2]), on aura [False, True]\n",
    "\n",
    "#Ainsi, nou on cherche à voir si toutes les cases correspondent, ainsi, on fait un np.all\n",
    "#ce qui nous assure qu'on a [True, True].\n",
    "\n",
    "#Ainsi, jets_numpy[:] nous renvoie tous les sous-tableaus de 2 cases,\n",
    "#et on regarde s'ils sont égaux à (1, 1) en utilisant np.all.\n",
    "\n",
    "\n",
    "print(\"\\nAvec sum et le parcours avec numpy\")\n",
    "%timeit sum(np.all(jets_numpy[:] == (1, 1), axis = -1)) / len(jets_numpy)\n",
    "\n",
    "\n",
    "print(\"\\nAvec le parcours en python natif\")\n",
    "%timeit len([0 for jet in jets_numpy if jet[0] == 1 and jet[1] == 1]) / len(jets_numpy)\n",
    "\n",
    "proba_empirique = np.sum(np.all(jets_numpy[:] == (1, 1), axis = -1)) / len(jets_numpy)\n",
    "\n",
    "\n",
    "\n",
    "#on peut simplement faire :\n",
    "print(f'\\n\\nproba empirique : {proba_empirique}\\nvrai proba : {1/36}')"
   ]
  },
  {
   "source": [
    "Quand on voit la différence de temps, il faut vraiment penser à utiliser np.sum sur les arrays numpy ! La majorité des fonctions de numpy sont en fait directement codées en C / C++ et sont précompilées. Ainsi, sur des tableaux compatibles (les arrays numpy, aussi appelés ndarray), il est vraiment très préférable d'appeler des fonctions optimisées, prévues à cet effet, plutôt que les fonctions natives de python."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ou alors compter toutes les possibilités :\n",
    "from collections import Counter\n",
    "d = Counter([(x, y) for x, y in jets_numpy]) #permet de compter le nombre de répétitions de chaque objet différents\n",
    "print(f'Nombre de (1, 1) : {d[(1,1)]}\\nNombre de (2, 2) : {d[(2,2)]}\\nNombre de (4, 6) : {d[(4,6)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soit nos jets : (X, Y), si on veut approximer P(Y = 1 | X = 1) :\n",
    "\n",
    "nb_jets_total = sum([d[(1, i)] for i in range(1, 7)]) #nombre total de jet où X = 1\n",
    "proba_empirique = d[(1,1)] / nb_jets_total\n",
    "\n",
    "print(f'proba empirique : {proba_empirique}\\nvrai proba : {1/6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si maintenant on regarde le nombre de fois où on a eu un 1 :\n",
    "\n",
    "p_x = sum([d[(1, i)] for i in range(1, 7)]) / len(jets_numpy) #P(X = 1)\n",
    "p_y = sum([d[(i, 1)] for i in range(1, 7)]) / len(jets_numpy) #P(Y = 1)\n",
    "\n",
    "print(f'proba empirique : {p_x + p_y}')\n",
    "\n",
    "#si vous êtes attentifs un truc devrait vous déranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On voit que la proba empirique approche 1/3\n",
    "\n",
    "# or la proba de n'avoir aucun 1 étant normalement de 5/6 * 5/6 = 25/36, on devrait avoir une proba empirique de 11/36 soit environ 1/3, mais pas tout à fait...\n",
    "# 1/3 = 0.3333 alors que 11/36 = 0,305555.\n",
    "# ici, on approche clairement plus de 1/3 du coup... Et c'est là que ça doit tout de suite vous alertez, on a trop de valeurs !\n",
    "# tout à l'heure on a prit tous les (1, y) et (x, 1) et on a donc compté les (1, 1) 2 fois.\n",
    "# Comme les (1,1) représentent 1/36 de l'échantillon total, si on les prend en compte 2 fois, on a alors (11/36 + 1/36 soit 1/3 de notre échantillon), tout est logique.\n",
    "print(f'proba empirique : {p_x + p_y - d[(1,1)] / len(jets_numpy)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve donc une proba beaucoup plus proche de ce que l'on attendait, donc approximez, mais pas trop en cours de stats (gardez ça pour la vie de tous les jours).\n",
    "Les 2 évènements au-dessus étant clairement indépendanst, enfin ça dépend de la génération aléatoire qui est probablement seulement pseudo-aléatoire, mais bon... C'est indépendant, ou presque, ...\n",
    "\n",
    "Truc sympa quand vous voulez approximer une proba ou un \n",
    "pourcentage dans la vie de tous les jours, l'erreur du calcul entre\n",
    "la multiplication et l'addition est souvent assez faible :\n",
    "\n",
    "Imaginons :\n",
    "* pour $1.05 * 1.05 = 1.1 + 0.05 * 0.05$\n",
    "* pour $5/6 * 5/6 = 2/3 + 1/6 * 1/6$\n",
    "\n",
    "Ainsi au dessus de 1, c'est une addition, en dessous, une soustraction, et on rajoute l'erreur si les deux sont au-dessus ou en-dessous de 1 ou on la soustrait si l'un est au-dessus de 1 et l'autre en-dessous. Erreur qui est alors la multiplication de la distance à 1 des 2 chiffres.\n",
    "\n",
    "Par exemple : \n",
    "* $1.1 \\times 1.2 \\ \\ = \\  1.3 + 0.02\\ = 1.32$\n",
    "* $1.1 \\times 0.9 \\ \\ = \\ 1 - 0.01 \\ \\ \\ \\ = 0.99$\n",
    "* $0.6 \\times 0.8 \\ \\ =\\  0.4 + 0.08 \\ = 0.48$\n",
    "* $1.25 \\times 0.8 = 1.05 - 0.05 = 1$\n",
    "\n",
    "Pour aussi partir un peu plus loin quand vous faisiez des dérivés en terminal (si jamais), vous auriez sûrement aimé connaitre : \n",
    "https://en.wikipedia.org/wiki/Automatic_differentiation#Automatic_differentiation_using_dual_numbers\n",
    "\n",
    "Ca paraît compliqué, car c'est la définition formelle mais en vrai, c'est hyper simple, soit votre variable $x + \\epsilon$ en argument, vous développez tout, et vous dîtes par définition que $\\epsilon \\rightarrow 0$ mais n'est pas égal à 0. Cependant, $\\epsilon^2$ étant extrêmement plus proche de 0 que $\\epsilon$, il n'est pas tant incorrect de dire que $\\epsilon^2 << \\epsilon$ est on peut donc l'ignorer.\n",
    "\n",
    "Par exemple : pour $f(x) = x^2$, on a alors $f(x + \\epsilon) = (x + \\epsilon)^2 = x^2 + 2x\\epsilon + \\epsilon^2 \\simeq x^2 + 2x\\epsilon$ soit la fonction normal ($x^2$) plus sa dérivée ($2x$) multiplié par $\\epsilon$.\n",
    "\n",
    "Cette équation est très liée à $f'(x) = lim_{h \\rightarrow 0}\\ \\ \\frac{f(x + h)}{h}$, la définition de la dérivée.\n",
    "\n",
    "Enfin bref, les erreurs très petites peuvent souvent être ignorées quand elles sont au carré, très pratique pour approximer !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dépendance\n",
    "\n",
    "Si on a maintenant deux variables aléatoires, mais que l'une dépend de l'autre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vous pouvez utiliser ctrl + entrée pour exécuter une cellule plusieurs fois d'affilé\n",
    "# ou shift + entrée pour exécuter la cellule courante, puis passer à la suivante.\n",
    "#soit par exemple, un truc assez classique :\n",
    "x = randint(1, 6)\n",
    "y = randint(1, x)\n",
    "(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tirages = [(x, randint(1, x)) for x in [randint(1, 6) for _ in range(100000)]]\n",
    "\n",
    "d = Counter(tirages)\n",
    "\n",
    "d = {k : v / len(tirages) for k, v in d.items()}\n",
    "d[(1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On peut alors donner la répartition empirique de la loi jointe\n",
    "p = np.zeros((6,6))\n",
    "for (i, j), v in d.items():\n",
    "    p[i - 1, j - 1] = v\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on veut maintenant la loi de X = i, sachant que Y = j :\n",
    "\n",
    "On applique la formule, directement, on a alors :\n",
    "    $P(X = i | Y = j) = \\frac{P(X = i, Y = j)}{P(Y = j)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On commence par calculer la loi de Y\n",
    "p_y = sum(p)\n",
    "print(p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ainsi, on peut avoir la loi de X, sachant Y :\n",
    "p_x = p / p_y\n",
    "print(p_x)\n",
    "# On voit alors, même si on le savait depuis le début que X et Y ne sont pas du tout indépendant..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un autre problème, assez connu des statistiques, est le suivant :\n",
    "\n",
    "Vous êtes testé positif à une maladie très rare, quelle est à posteriori la probabilité que vous ayez vraiment cette maladie ?\n",
    "\n",
    "https://www.youtube.com/watch?v=lG4VkPoG3ko\n",
    "\n",
    "La réponse est alors, tout dépend de la rareté de la maladie et de l'accuracy du test.\n",
    "\n",
    "Si nous simulons un échantillon de 10 000 personnes :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "#soit p l'accuracy du test (en anglais, accuracy et precision sont deux données bien distinctes.) :\n",
    "# https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "p = 0.99\n",
    "\n",
    "#soit apriori, la probabilité d'avoir la maladie :\n",
    "apriori = 0.01\n",
    "\n",
    "#On a alors le groupe positif :\n",
    "positif = 0\n",
    "negatif = 0\n",
    "for _ in range(10000):\n",
    "    if random() < apriori:\n",
    "        positif += 1\n",
    "    else:\n",
    "        negatif += 1\n",
    "print(f'Positifs : {positif}\\nNégatifs : {negatif}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vrai_positif = 0\n",
    "faux_positif = 0\n",
    "vrai_negatif = 0\n",
    "faux_negatif = 0\n",
    "for _ in range(positif):\n",
    "    if random() <= p:\n",
    "        vrai_positif += 1\n",
    "    else:\n",
    "        faux_negatif += 1\n",
    "\n",
    "for _ in range(negatif):\n",
    "    if random() <= p:\n",
    "        vrai_negatif += 1\n",
    "    else:\n",
    "        faux_positif += 1\n",
    "\n",
    "\n",
    "print(f'Vrai positifs : {vrai_positif}\\nFaux positifs : {faux_positif}\\nPositifs au tests : {vrai_positif + faux_positif}\\n\\nVrai négatifs : {vrai_negatif}\\nFaux négatif : {faux_negatif}\\nNégatifs au tests : {vrai_negatif + faux_negatif}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut voir ces stats comme:\n",
    "\n",
    "Il est très peu probable que vous ayez cette maladie, ainsi si le test vous donne négatif, alors vous êtes presque sûr de d'être vraiment négatif (ici, notre chance d'être Faux Négatif est égale à $\\frac{Faux\\ Négatif}{Négatif\\ Au\\ Test}$ (2/9809 avec mes données)), alors que si vous êtes testé positif, il est autant probable que le teste dise n'importe quoi ou que vous ayez vraiment la maladie (99/191 dans mes données). \n",
    "\n",
    "Cela est dû aux valeurs opposés de l'accuracy et de la rareté de la maladie, si on change le ratio, alors on changera l'information que nous apporte ce test. On voit assez bien que si la maladie est plus rare, il y aura en fait plus de chance que le test rate, plutôt que vous ayez vriament la maladie. Ainsi, pour des valeurs un peu plus extrême pour la probabilité à priori d'avoir la maladie, le test n'apporte que très peu d'information.\n",
    "\n",
    "Si on va un peu plus loin, on parle ici d'un test qu'on fait avec l'apriori de base, c'est à dire que vous avez autant de chance d'avoir cette maladie que quelqu'un d'autre, mais, dans un contexte plus réel, si vous demandez à vous faire dépister, ou que votre médecin décide de vous dépister, vous n'avez généralement pas vraiment l'apriori de base. En effet, les symptômes, les gênes, et tous les autres facteurs de risques peuvent venir appuyer le test, (en locurence c'est plutôt le test qui vient appuyer ces données).\n",
    "\n",
    "Le résultat du test viendra alors update vos chances de vraiment avoir cette maladie. Il ne faut pas voir le résultat comme une réponse, mais comme une indication (plus ou moins fiable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Chance d'être positif sachant que le test est positif : {vrai_positif/(vrai_positif + faux_positif)}  (C'est ça que l'on appelle precision en anglais)\")\n",
    "print(f\"Chance d'être négatif sachant que le test est négatif : {vrai_negatif/(vrai_negatif + faux_negatif)}\")\n",
    "print(f\"Chance d'être testé positif sachant que vous êtes positif : {vrai_positif/(vrai_positif + faux_negatif)} (C'est ça que l'on appelle recall en anglais)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "toc-autonumbering": false,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}